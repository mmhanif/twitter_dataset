{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve tweets using Tweepy and store in a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assertpy import assert_that    # Better assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pre-requisite is to set up developer access for your Twitter account and then create a Twitter application that will generate the API credentials we will use below to access the Twitter API. \n",
    "\n",
    "The code below assume you have stored the credentials in a \"keys.json\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keys.json\", \"r\") as f:\n",
    "    keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= keys[\"consumer\"][\"api\"]\n",
    "consumer_secret= keys[\"consumer\"][\"secret\"]\n",
    "access_token= keys[\"access\"][\"token\"]\n",
    "access_token_secret= keys[\"access\"][\"secret\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that authenticates you with Twitter and returns a tweepy.API object. I've put this in a function as I will refresh the session with Twitter intermittently. This is probably not needed but a blog post I read suggested that long-running session tend to slow down after a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_api():\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in search terms from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keywords.txt\", \"r\") as f:\n",
    "    keywords = [word.strip('\\n') for word in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the query string we will use for a given search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(search_string):\n",
    "    \"\"\"\n",
    "    Query for both search_string and #search_string.\n",
    "    If search_string contains spaces then wrap in double quotes (and remove spaces from hashtag).\n",
    "    Filter out any retweets\n",
    "    \"\"\"\n",
    "    words = search_string.split()\n",
    "    query = '\\\"' + search_string + '\\\"' if len(words) > 1 else search_string\n",
    "    query = query + ' #' + \"\".join(words)\n",
    "    query = query + \" -filter:retweets\"\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_that(search_query(\"wildfires\")).is_equal_to(\"wildfires #wildfires -filter:retweets\")\n",
    "assert_that(search_query(\"body bag\")).is_equal_to('\"body bag\" #bodybag -filter:retweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over keywords, create search query, perform search and store results in a Pandas dataframe\n",
    "Every 10 keywords, refresh session with Twitter (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "count = 0\n",
    "for keyword in keywords:\n",
    "    if count % 10 == 0:\n",
    "        api = tw_api()\n",
    "    count += 1\n",
    "    print(\"(%d/%d) Querying for %s\" % (count, len(keywords), keyword))\n",
    "    cursor = tw.Cursor(api.search,\n",
    "              q=search_query(keyword),\n",
    "              count=100,\n",
    "              tweet_mode='extended',\n",
    "              lang=\"en\")\n",
    "    tweets = cursor.items(100)\n",
    "    data = [[tweet.full_text.encode(\"ascii\", \"ignore\").decode(), keyword] for tweet in tweets]\n",
    "    df = pd.DataFrame(columns=[\"text\", \"search_term\"], data=data)\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the keyword specific dataframes into one uber dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.concat(dataframes, ignore_index=True)\n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip any extraneous whitespace and drop any duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.text = tweets_df.text.apply(lambda s: s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets_df.drop_duplicates(subset='text', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (twitter)",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
